[2016-01-14 22:48:57,360] DEBUG preRegister called. Server=com.sun.jmx.mbeanserver.JmxMBeanServer@66d3c617, name=log4j:logger=state.change.logger (state.change.logger)
[2016-01-14 22:49:29,150] DEBUG preRegister called. Server=com.sun.jmx.mbeanserver.JmxMBeanServer@66d3c617, name=log4j:logger=state.change.logger (state.change.logger)
[2016-01-14 22:50:14,159] DEBUG preRegister called. Server=com.sun.jmx.mbeanserver.JmxMBeanServer@66d3c617, name=log4j:logger=state.change.logger (state.change.logger)
[2016-01-14 22:50:48,744] DEBUG preRegister called. Server=com.sun.jmx.mbeanserver.JmxMBeanServer@66d3c617, name=log4j:logger=state.change.logger (state.change.logger)
[2016-01-14 22:51:42,083] DEBUG preRegister called. Server=com.sun.jmx.mbeanserver.JmxMBeanServer@66d3c617, name=log4j:logger=state.change.logger (state.change.logger)
[2016-01-14 22:56:59,481] DEBUG preRegister called. Server=com.sun.jmx.mbeanserver.JmxMBeanServer@66d3c617, name=log4j:logger=state.change.logger (state.change.logger)
[2016-01-14 22:57:20,580] TRACE Controller 0 epoch 8 started leader election for partition [twitterstream,0] (state.change.logger)
[2016-01-14 22:57:20,596] ERROR Controller 0 epoch 8 initiated state change for partition [twitterstream,0] from OfflinePartition to OnlinePartition failed (state.change.logger)
kafka.common.NoReplicaOnlineException: No replica for partition [twitterstream,0] is alive. Live brokers are: [Set()], Assigned replicas are: [List(0)]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:75)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:205)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:120)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:117)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:778)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:777)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:117)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:70)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:332)
	at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:163)
	at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:84)
	at kafka.server.ZookeeperLeaderElector$$anonfun$startup$1.apply$mcZ$sp(ZookeeperLeaderElector.scala:50)
	at kafka.server.ZookeeperLeaderElector$$anonfun$startup$1.apply(ZookeeperLeaderElector.scala:48)
	at kafka.server.ZookeeperLeaderElector$$anonfun$startup$1.apply(ZookeeperLeaderElector.scala:48)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.server.ZookeeperLeaderElector.startup(ZookeeperLeaderElector.scala:48)
	at kafka.controller.KafkaController$$anonfun$startup$1.apply$mcV$sp(KafkaController.scala:681)
	at kafka.controller.KafkaController$$anonfun$startup$1.apply(KafkaController.scala:677)
	at kafka.controller.KafkaController$$anonfun$startup$1.apply(KafkaController.scala:677)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController.startup(KafkaController.scala:677)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:188)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:37)
	at kafka.Kafka$.main(Kafka.scala:67)
	at kafka.Kafka.main(Kafka.scala)
[2016-01-14 22:57:20,772] TRACE Controller 0 epoch 8 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:6,ControllerEpoch:7) to broker 0 for partition twitterstream-0 (state.change.logger)
[2016-01-14 22:57:20,801] TRACE Controller 0 epoch 8 changed state of replica 0 for partition [twitterstream,0] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-01-14 22:57:20,802] TRACE Controller 0 epoch 8 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:6,ControllerEpoch:7) to broker 0 for partition [twitterstream,0] (state.change.logger)
[2016-01-14 22:57:20,806] TRACE Controller 0 epoch 8 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:6,ControllerEpoch:7) to broker 0 for partition twitterstream-0 (state.change.logger)
[2016-01-14 22:57:20,807] TRACE Controller 0 epoch 8 started leader election for partition [twitterstream,0] (state.change.logger)
[2016-01-14 22:57:20,821] TRACE Controller 0 epoch 8 elected leader 0 for Offline partition [twitterstream,0] (state.change.logger)
[2016-01-14 22:57:20,823] TRACE Controller 0 epoch 8 changed partition [twitterstream,0] from OfflinePartition to OnlinePartition with leader 0 (state.change.logger)
[2016-01-14 22:57:20,823] TRACE Controller 0 epoch 8 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:7,ControllerEpoch:8) to broker 0 for partition [twitterstream,0] (state.change.logger)
[2016-01-14 22:57:20,824] TRACE Controller 0 epoch 8 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:7,ControllerEpoch:8) to broker 0 for partition twitterstream-0 (state.change.logger)
[2016-01-14 22:57:20,863] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:6,ControllerEpoch:7),ReplicationFactor:1),AllReplicas:0) for partition [twitterstream,0] in response to UpdateMetadata request sent by controller 0 epoch 8 with correlation id 0 (state.change.logger)
[2016-01-14 22:57:20,868] TRACE Controller 0 epoch 8 received response {error_code=0} for a request sent to broker Node(0, 192.168.0.17, 9092) (state.change.logger)
[2016-01-14 22:57:20,928] TRACE Broker 0 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:6,ControllerEpoch:7),ReplicationFactor:1),AllReplicas:0) correlation id 1 from controller 0 epoch 8 for partition [twitterstream,0] (state.change.logger)
[2016-01-14 22:57:20,934] TRACE Broker 0 handling LeaderAndIsr request correlationId 1 from controller 0 epoch 8 starting the become-leader transition for partition [twitterstream,0] (state.change.logger)
[2016-01-14 22:57:20,948] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 0 epoch 8 with correlation id 1 for partition [twitterstream,0] (state.change.logger)
[2016-01-14 22:57:20,952] TRACE Broker 0 completed LeaderAndIsr request correlationId 1 from controller 0 epoch 8 for the become-leader transition for partition [twitterstream,0] (state.change.logger)
[2016-01-14 22:57:20,958] TRACE Controller 0 epoch 8 received response {error_code=0,partitions=[{topic=twitterstream,partition=0,error_code=0}]} for a request sent to broker Node(0, 192.168.0.17, 9092) (state.change.logger)
[2016-01-14 22:57:20,959] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:6,ControllerEpoch:7),ReplicationFactor:1),AllReplicas:0) for partition [twitterstream,0] in response to UpdateMetadata request sent by controller 0 epoch 8 with correlation id 2 (state.change.logger)
[2016-01-14 22:57:20,960] TRACE Controller 0 epoch 8 received response {error_code=0} for a request sent to broker Node(0, 192.168.0.17, 9092) (state.change.logger)
[2016-01-14 22:57:20,961] TRACE Broker 0 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:7,ControllerEpoch:8),ReplicationFactor:1),AllReplicas:0) correlation id 3 from controller 0 epoch 8 for partition [twitterstream,0] (state.change.logger)
[2016-01-14 22:57:20,961] TRACE Broker 0 handling LeaderAndIsr request correlationId 3 from controller 0 epoch 8 starting the become-leader transition for partition [twitterstream,0] (state.change.logger)
[2016-01-14 22:57:20,962] INFO Broker 0 skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 0 epoch 8 for partition [twitterstream,0] since it is already the leader for the partition. (state.change.logger)
[2016-01-14 22:57:20,962] TRACE Broker 0 completed LeaderAndIsr request correlationId 3 from controller 0 epoch 8 for the become-leader transition for partition [twitterstream,0] (state.change.logger)
[2016-01-14 22:57:20,963] TRACE Controller 0 epoch 8 received response {error_code=0,partitions=[{topic=twitterstream,partition=0,error_code=0}]} for a request sent to broker Node(0, 192.168.0.17, 9092) (state.change.logger)
[2016-01-14 22:57:20,964] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:7,ControllerEpoch:8),ReplicationFactor:1),AllReplicas:0) for partition [twitterstream,0] in response to UpdateMetadata request sent by controller 0 epoch 8 with correlation id 4 (state.change.logger)
[2016-01-14 22:57:20,965] TRACE Controller 0 epoch 8 received response {error_code=0} for a request sent to broker Node(0, 192.168.0.17, 9092) (state.change.logger)
